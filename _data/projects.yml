- layout: top-middle
  #name: Deterministic Routing between Layout Abstractions for Multi-Scale Classification of Visually Rich Documents <br/><br/>
  #link: <a href="www.researchgate.net/publication/333859687_Visual_Segmentation_for_Information_Extraction_from_Heterogeneous_Visually_Rich_Documents" target="_blank">The Ohio State University</a>
  #github: Github page for project (eg. sproogen/modern-resume-theme)(optional)
  #quote: 
   #<img src="assets/laddernet_workflow.jpg" alt="Laddernet Workflow" width="500" height="170" style="align:center">
  description: <strong>Deterministic Routing between Layout Abstractions for Multi-Scale Classification of Visually Rich Documents</strong><br/><br/> <strong>TLDR:</strong> A visually rich document refers to a document where visual features play an important role in semantics. We propose a fast, multi-scale classifier for such documents. For fast inference, we define an attention-like operator that extracts visual features from a hierarchical abstraction defined for each document. We obtain state-of-the-art results on multiple benchmark datasets.<br/><br/> <strong>Conference:</strong> 28th International Joint Conference on Artificial Intelligence (IJCAI), 2019 <br/> <strong>Authors:</strong> Ritesh Sarkhel, Arnab Nandi <br/> <strong>Full-text</strong> -- <a href="https://github.com/sarkhelritesh/sarkhelritesh.github.io/blob/master/papers/ladderNet.pdf"><u>here</u></a>, <strong>Slides</strong> -- <a href="https://github.com/sarkhelritesh/sarkhelritesh.github.io/blob/master/slides/ladderNet_PPT.pdf"><u>here</u></a> <br/>
  
- layout: top-middle
  name: Visual Segmentation for Information Extraction from Heterogeneous Visually Rich Documents <br/><br/>
  #link: <a href="www.researchgate.net/publication/333859687_Visual_Segmentation_for_Information_Extraction_from_Heterogeneous_Visually_Rich_Documents" target="_blank">The Ohio State University</a>
  #github: Github page for project (eg. sproogen/modern-resume-theme)(optional)
  #quote: 
   #<img src="assets/segment_select_workflow.jpg" alt="Segment-Select Workflow" width="500" height="190" style="align:center">
  description: <strong>TLDR:</strong> We hypothesize that every visually rich document is comprised of a set of isolated, semantically coherent areas called logical blocks. We propose VS2, a divide-and-conquer approach for information extraction leveraging this bag-of-logical-blocks representation. Our end-to-end workflow does not utilize any type or format specific features, making it robust towards heterogeneous documents.<br/><br/> <strong>Conference:</strong> International Conference on Management of Data (SIGMOD), 2019 <br/> <strong>Authors:</strong> Ritesh Sarkhel, Arnab Nandi <br/> <strong>Full-text</strong> -- <a href="https://github.com/sarkhelritesh/sarkhelritesh.github.io/blob/master/papers/segment_Select.pdf"><u>here</u></a>, <strong>Slides</strong> -- <a href="https://github.com/sarkhelritesh/sarkhelritesh.github.io/blob/master/slides/segment_Select_PPT.pdf"><u>here</u></a> <br/>
  
  
  
 
  
  
 
