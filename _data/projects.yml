- layout: top-middle
  name: Deterministic Routing between Layout Abstractions for Multi-Scale classification <br/> of Visually Rich Documents
  #link: <a href="www.researchgate.net/publication/333859687_Visual_Segmentation_for_Information_Extraction_from_Heterogeneous_Visually_Rich_Documents" target="_blank">The Ohio State University</a>
  #github: Github page for project (eg. sproogen/modern-resume-theme)(optional)
  quote: 
    <img src="assets/laddernet_workflow.jpg" alt="Laddernet Workflow" width="500" height="170" style="align:center">
  description: A visually rich document refers to a structured or semi-structured document where visual features play an important role in semantics. We propose a fast, multi-scale classifier for such documents. For fast inference, we define an attention-like operator that extracts visual features from a hierarchical abstraction defined for each document. Discriminative features are extracted using a depth-separable convolutional network. We obtained state-of-the-art results on multiple benchmark datasets.<br/><br/> <strong>Authors:</strong> Ritesh Sarkhel, Arnab Nandi <br/> <strong>Full-text</strong> -- <a href="https://github.com/sarkhelritesh/sarkhelritesh.github.io/blob/master/papers/ladderNet.pdf">here</a>, <strong>Slides</strong> -- <a href="https://github.com/sarkhelritesh/sarkhelritesh.github.io/blob/master/slides/ladderNet_PPT.pdf">here</a>
  
- layout: top-middle
  name: Visual Segmentation for Information Extraction from Heterogeneous Visually Rich Documents
  #link: <a href="www.researchgate.net/publication/333859687_Visual_Segmentation_for_Information_Extraction_from_Heterogeneous_Visually_Rich_Documents" target="_blank">The Ohio State University</a>
  #github: Github page for project (eg. sproogen/modern-resume-theme)(optional)
  quote: 
    <img src="assets/segment_select_workflow.jpg" alt="Segment-Select Workflow" width="500" height="250" style="align:center">
  description: We hypothesize that every visually rich document is comprised of a set of isolated, semantically coherent areas called logical blocks. We propose VS2, a divide-and-conquer approach for information extraction leveraging this bag-of-logical-blocks representation. To mitigate the dependency on expensive gold-standard annotations, we train the extractors on a text corpus following a distance supervision approach. The end-to-end workflow starting from deriving the logical blocks to extracting named entities does not utilize any document type or format specific features, making our method robust towards heterogeneous documents.<br/><br/> <strong>Authors:</strong> Ritesh Sarkhel, Arnab Nandi <br/> <strong>Full-text</strong> -- <a href="https://github.com/sarkhelritesh/sarkhelritesh.github.io/blob/master/papers/segment_Select.pdf">here</a>, <strong>Slides</strong> -- <a href="https://github.com/sarkhelritesh/sarkhelritesh.github.io/blob/master/slides/segment_Select_PPT.pdf">here</a> <br/><br/> A more exhaustive list of publications can be found <a href="https://scholar.google.com/citations?user=6FE__csAAAAJ&hl=en">here</a>
  
  
  
 
  
  
 
